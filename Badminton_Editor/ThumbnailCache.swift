import Foundation
import AVFoundation
import UIKit
import SwiftUI
import Photos
import VideoToolbox

// MARK: - PHAsset Support (iOS Photo Library)

extension ThumbnailCache {
    /// Ë®≠ÂÆö PHAssetÔºå‰∏¶Ëá™ÂãïËôïÁêÜ iCloud„ÄÅHEVC„ÄÅÈåØË™§Ë®∫Êñ∑ËàáÊó•Ë™å
    func setPHAsset(_ phAsset: PHAsset) {
        print("ThumbnailCache: setPHAsset called. localIdentifier=\(phAsset.localIdentifier), mediaType=\(phAsset.mediaType.rawValue), duration=\(phAsset.duration)")

        // ÂÖàÊ∏ÖÁ©∫Âø´Âèñ
        self.clearCache()

        // ÂèñÂæó AVAsset
        let options = PHVideoRequestOptions()
        options.isNetworkAccessAllowed = true // ÂÖÅË®±Ëá™Âãï‰∏ãËºâ iCloud ÂΩ±Áâá
        options.deliveryMode = .highQualityFormat
        options.version = .current

        PHImageManager.default().requestAVAsset(forVideo: phAsset, options: options) { [weak self] avAsset, audioMix, info in
            guard let self = self else { return }

            if let info = info {
                if let isInCloud = info[PHImageResultIsInCloudKey] as? Bool, isInCloud {
                    print("ThumbnailCache: PHAsset is in iCloud, will auto-download if needed.")
                }
                if let cancelled = info[PHImageCancelledKey] as? Bool, cancelled {
                    print("ThumbnailCache: PHAsset request was cancelled.")
                }
                if let error = info[PHImageErrorKey] as? NSError {
                    print("ThumbnailCache: PHAsset request error: \(error.localizedDescription)")
                }
            }

            guard let avAsset = avAsset else {
                print("ThumbnailCache: Failed to get AVAsset from PHAsset. info=\(String(describing: info))")
                
                // ÂòóË©¶‰ΩøÁî® PHImageManager ÁöÑÂÖ∂‰ªñÈÅ∏È†Ö‰ΩúÁÇ∫ÂÇôÁî®ÊñπÊ°à
                self.tryAlternativeVideoRequest(for: phAsset)
                return
            }

            Task {
                // Ê™¢Êü• AVAsset ÊòØÂê¶ÂèØÊí≠Êîæ„ÄÅÂèØËÆÄÂèñ
                if let urlAsset = avAsset as? AVURLAsset {
                    print("ThumbnailCache: AVURLAsset url=\(urlAsset.url)")
                    print("ThumbnailCache: URL scheme=\(urlAsset.url.scheme ?? "nil"), pathExtension=\(urlAsset.url.pathExtension)")
                }

                // Ê™¢Êü• HEVC ÊîØÊè¥
                let hevcSupported = self.checkHEVCSupport()
                print("ThumbnailCache: HEVC hardware decode supported: \(hevcSupported)")

                // duration (async for iOS 16+)
                var durationSeconds: Double = 0
                if #available(iOS 16.0, *) {
                    do {
                        let duration = try await avAsset.load(.duration)
                        durationSeconds = duration.seconds
                    } catch {
                        print("ThumbnailCache: Failed to load duration: \(error)")
                        print("ThumbnailCache: Trying alternative asset loading...")
                        self.tryAlternativeVideoRequest(for: phAsset)
                        return
                    }
                } else {
                    durationSeconds = avAsset.duration.seconds
                }

                print("ThumbnailCache: AVAsset duration=\(durationSeconds), isPlayable=\(avAsset.isPlayable), isReadable=\(avAsset.isReadable)")

                // ÂàóÂá∫ÊâÄÊúâ video track ÁöÑ codec type
                var videoTracks: [AVAssetTrack] = []
                if #available(iOS 16.0, *) {
                    do {
                        videoTracks = try await avAsset.loadTracks(withMediaType: .video)
                    } catch {
                        print("ThumbnailCache: Failed to load video tracks: \(error)")
                    }
                } else {
                    videoTracks = avAsset.tracks(withMediaType: .video)
                }
                for (idx, track) in videoTracks.enumerated() {
                    var dimensions = CGSize.zero
                    if #available(iOS 16.0, *) {
                        do {
                            dimensions = try await track.load(.naturalSize)
                        } catch {
                            print("ThumbnailCache: Failed to load naturalSize: \(error)")
                        }
                    } else {
                        dimensions = track.naturalSize
                    }
                    var formatDescriptions: [CMFormatDescription] = []
                    if #available(iOS 16.0, *) {
                        do {
                            let rawFormats = try await track.load(.formatDescriptions)
                            formatDescriptions = rawFormats.compactMap { $0 as? CMFormatDescription }
                        } catch {
                            print("ThumbnailCache: Failed to load formatDescriptions: \(error)")
                        }
                    } else {
                        formatDescriptions = track.formatDescriptions as? [CMFormatDescription] ?? []
                    }
                    if let formatDesc = formatDescriptions.first {
                        let codecType = CMFormatDescriptionGetMediaSubType(formatDesc)
                        let codecStr = self.FourCharCodeToString(codecType)
                        print("ThumbnailCache: VideoTrack[\(idx)] codec=\(codecStr), dimensions=\(dimensions)")
                        
                        // ÁâπÂà•Ê™¢Êü• HEVC Ê†ºÂºè
                        if codecStr == "hvc1" || codecStr == "hev1" {
                            print("ThumbnailCache: ‚ö†Ô∏è HEVC video detected! This may cause issues on some devices.")
                            print("ThumbnailCache: Consider transcoding to H.264 for better compatibility.")
                            
                            // Ê™¢Êü•ÊòØÂê¶ÂèØ‰ª•ÁîüÊàêÁ∏ÆÂúñ
                            self.testThumbnailGeneration(for: avAsset, at: 1.0)
                            
                            // Êèê‰æõËΩâÁ¢ºÈÅ∏È†Ö
                            print("ThumbnailCache: üîÑ HEVC detected - offering H.264 transcoding option")
                            self.offerTranscodingOption(for: phAsset, hevcAsset: avAsset)
                        } else {
                            print("ThumbnailCache: ‚úÖ Non-HEVC video detected (codec: \(codecStr)). No transcoding needed.")
                            
                            // ÁÇ∫‰∫ÜÊ∏¨Ë©¶ÁõÆÁöÑÔºå‰πüÂèØ‰ª•Êèê‰æõËΩâÁ¢ºÈÅ∏È†Ö
                            #if DEBUG
                            print("ThumbnailCache: üß™ DEBUG: Offering transcoding option for testing")
                            self.offerTranscodingOption(for: phAsset, hevcAsset: avAsset)
                            #endif
                        }
                    } else {
                        print("ThumbnailCache: ‚ö†Ô∏è No format description found for video track")
                    }
                }

                // Ê™¢Êü• AVAsset ÊòØÂê¶ÁúüÁöÑÂèØÁî®
                if !avAsset.isPlayable || !avAsset.isReadable {
                    print("ThumbnailCache: ‚ùå AVAsset is not playable or readable")
                    self.tryAlternativeVideoRequest(for: phAsset)
                    return
                }

                // Ë®≠ÂÆö asset ‰∏¶ÁîüÊàêÁ∏ÆÂúñ
                DispatchQueue.main.async {
                    self.setAsset(avAsset)
                }
            }
        }
    }

    /// FourCharCode ËΩâ String (for codec type)
    func FourCharCodeToString(_ code: FourCharCode) -> String {
        let n = Int(code)
        var s: String = ""
        s.append(Character(UnicodeScalar((n >> 24) & 255)!))
        s.append(Character(UnicodeScalar((n >> 16) & 255)!))
        s.append(Character(UnicodeScalar((n >> 8) & 255)!))
        s.append(Character(UnicodeScalar(n & 255)!))
        return s
    }
    
    /// Ê™¢Êü• HEVC Á°¨È´îËß£Á¢ºÊîØÊè¥
    private func checkHEVCSupport() -> Bool {
        // Ê™¢Êü•Ë®≠ÂÇôÊòØÂê¶ÊîØÊè¥ HEVC Á°¨È´îËß£Á¢º
        if #available(iOS 11.0, *) {
            return VTIsHardwareDecodeSupported(kCMVideoCodecType_HEVC)
        }
        return false
    }
    
    /// Ê∏¨Ë©¶Á∏ÆÂúñÁîüÊàêÊòØÂê¶ÂèØË°å
    private func testThumbnailGeneration(for asset: AVAsset, at time: TimeInterval) {
        let generator = AVAssetImageGenerator(asset: asset)
        generator.maximumSize = CGSize(width: 160, height: 90) // ËºÉÂ∞èÂ∞∫ÂØ∏Ê∏¨Ë©¶
        generator.appliesPreferredTrackTransform = true
        
        let cmTime = CMTime(seconds: time, preferredTimescale: 600)
        
        DispatchQueue.global(qos: .utility).async {
            generator.generateCGImagesAsynchronously(forTimes: [NSValue(time: cmTime)]) { _, cgImage, _, result, error in
                DispatchQueue.main.async {
                    if let error = error {
                        print("ThumbnailCache: ‚ùå HEVC thumbnail test failed: \(error.localizedDescription)")
                    } else if cgImage != nil {
                        print("ThumbnailCache: ‚úÖ HEVC thumbnail test succeeded")
                    } else {
                        print("ThumbnailCache: ‚ö†Ô∏è HEVC thumbnail test returned no image")
                    }
                }
            }
        }
    }
    
    /// ÂòóË©¶Êõø‰ª£ÁöÑÂΩ±ÁâáË´ãÊ±ÇÊñπÊ≥ï
    private func tryAlternativeVideoRequest(for phAsset: PHAsset) {
        print("ThumbnailCache: Trying alternative video request with compatibility mode...")
        
        let options = PHVideoRequestOptions()
        options.isNetworkAccessAllowed = true
        options.deliveryMode = .mediumQualityFormat // Èôç‰ΩéÂìÅË≥™Ë¶ÅÊ±Ç
        options.version = .current
        
        // ÂòóË©¶Ë´ãÊ±ÇÁõ∏ÂÆπÊ†ºÂºè
        PHImageManager.default().requestAVAsset(forVideo: phAsset, options: options) { [weak self] avAsset, audioMix, info in
            guard let self = self else { return }
            
            if let avAsset = avAsset {
                print("ThumbnailCache: ‚úÖ Alternative request succeeded")
                DispatchQueue.main.async {
                    self.setAsset(avAsset)
                }
            } else {
                print("ThumbnailCache: ‚ùå Alternative request also failed")
                
                // ÊúÄÂæåÂòóË©¶Ôºö‰ΩøÁî® PHImageManager Áõ¥Êé•Ë´ãÊ±ÇÂúñÁâá‰ΩúÁÇ∫Á∏ÆÂúñ
                self.tryImageFallback(for: phAsset)
            }
        }
    }
    
    /// ÊúÄÂæåÂÇôÁî®ÊñπÊ°àÔºö‰ΩøÁî®ÈùúÊÖãÂúñÁâá‰ΩúÁÇ∫Á∏ÆÂúñ
    private func tryImageFallback(for phAsset: PHAsset) {
        print("ThumbnailCache: Using image fallback for unsupported video")
        
        let options = PHImageRequestOptions()
        options.isNetworkAccessAllowed = true
        options.deliveryMode = .highQualityFormat
        options.resizeMode = .exact
        
        let targetSize = CGSize(width: 240, height: 135)
        
        PHImageManager.default().requestImage(
            for: phAsset,
            targetSize: targetSize,
            contentMode: .aspectFill,
            options: options
        ) { [weak self] image, info in
            guard let self = self, let image = image else {
                print("ThumbnailCache: ‚ùå Image fallback also failed")
                return
            }
            
            print("ThumbnailCache: ‚úÖ Using static image as video thumbnail")
            
            // Â∞áÈùúÊÖãÂúñÁâá‰ΩúÁÇ∫ 0.0 ÊôÇÈñìÈªûÁöÑÁ∏ÆÂúñ
            DispatchQueue.main.async {
                let key = NSNumber(value: 0.0)
                let cost = Int(self.thumbnailSize.width * self.thumbnailSize.height * 4)
                self.cache.setObject(image, forKey: key, cost: cost)
                self.thumbnails[0.0] = image
            }
        }
    }
    
    // MARK: - Video Transcoding Support
    
    /// Êèê‰æõ HEVC ËΩâ H.264 ËΩâÁ¢ºÈÅ∏È†Ö
    private func offerTranscodingOption(for phAsset: PHAsset, hevcAsset: AVAsset) {
        print("ThumbnailCache: üîÑ Offering H.264 transcoding for HEVC video...")
        
        // Ê™¢Êü•ÊòØÂê¶ÂèØ‰ª•ËΩâÁ¢º
        guard canTranscodeToH264(asset: hevcAsset) else {
            print("ThumbnailCache: ‚ùå Asset cannot be transcoded to H.264")
            return
        }
        
        // ÁôºÈÄÅËΩâÁ¢ºÈÄöÁü•Áµ¶ UI Â±§ÔºåÂåÖÂê´Êõ¥Â§öË©≥Á¥∞Ë≥áË®ä
        DispatchQueue.main.async {
            NotificationCenter.default.post(
                name: NSNotification.Name("HEVCTranscodingAvailable"),
                object: nil,
                userInfo: [
                    "phAsset": phAsset,
                    "hevcAsset": hevcAsset,
                    "thumbnailCache": self,
                    "videoInfo": [
                        "duration": hevcAsset.duration.seconds,
                        "isPlayable": hevcAsset.isPlayable,
                        "hasVideoTracks": !hevcAsset.tracks(withMediaType: .video).isEmpty
                    ]
                ]
            )
        }
    }
    
    /// Ê™¢Êü•ÊòØÂê¶ÂèØ‰ª•ËΩâÁ¢ºÁÇ∫ H.264
    private func canTranscodeToH264(asset: AVAsset) -> Bool {
        // Ê™¢Êü• AVAssetExportSession ÊòØÂê¶ÊîØÊè¥ H.264 ËΩâÁ¢º
        let supportedTypes = AVAssetExportSession.exportPresets(compatibleWith: asset)
        return supportedTypes.contains(AVAssetExportPresetMediumQuality) ||
               supportedTypes.contains(AVAssetExportPreset1280x720) ||
               supportedTypes.contains(AVAssetExportPreset1920x1080)
    }
    
    /// Âü∑Ë°å HEVC ËΩâ H.264 ËΩâÁ¢º
    func transcodeHEVCToH264(
        phAsset: PHAsset,
        hevcAsset: AVAsset,
        quality: TranscodingQuality = .medium,
        progressHandler: @escaping (Float) -> Void,
        completion: @escaping (Result<AVAsset, TranscodingError>) -> Void
    ) {
        print("ThumbnailCache: üîÑ Starting HEVC to H.264 transcoding...")
        
        // Ê™¢Êü•ÊòØÂê¶Â∑≤Á∂ìÊúâÊ≠£Âú®ÈÄ≤Ë°åÁöÑËΩâÁ¢º
        if isTranscoding {
            print("ThumbnailCache: ‚ö†Ô∏è Transcoding already in progress")
            completion(.failure(.unknownError))
            return
        }
        
        // Âª∫Á´ãËº∏Âá∫ URL
        let outputURL = createTranscodedVideoURL(for: phAsset)
        
        // Âà™Èô§Â∑≤Â≠òÂú®ÁöÑÊ™îÊ°à
        try? FileManager.default.removeItem(at: outputURL)
        
        // Âª∫Á´ã export sessionÔºå‰ΩøÁî®Êô∫ËÉΩÈ†êË®≠ÈÅ∏Êìá
        var exportSession = AVAssetExportSession(asset: hevcAsset, presetName: quality.exportPreset)
        
        // Â¶ÇÊûú‰∏ªË¶ÅÈ†êË®≠Â§±ÊïóÔºåÂòóË©¶ÂÇôÁî®È†êË®≠
        if exportSession == nil, let fallbackPreset = quality.fallbackPreset {
            print("ThumbnailCache: Primary preset failed, trying fallback preset...")
            exportSession = AVAssetExportSession(asset: hevcAsset, presetName: fallbackPreset)
        }
        
        guard let validExportSession = exportSession else {
            print("ThumbnailCache: ‚ùå Failed to create AVAssetExportSession with any preset")
            completion(.failure(.exportSessionCreationFailed))
            return
        }
        
        // ÂÑ≤Â≠ò export session ‰ª•‰æøÂèñÊ∂à
        activeExportSession = validExportSession
        
        // Ë®≠ÂÆöËº∏Âá∫
        validExportSession.outputURL = outputURL
        validExportSession.outputFileType = .mp4
        validExportSession.shouldOptimizeForNetworkUse = true
        
        // Ë®≠ÂÆöË¶ñÈ†ªÁ∑®Á¢ºË®≠ÂÆöÔºåÁ¢∫‰øùËº∏Âá∫ÁÇ∫ H.264
        validExportSession.metadata = nil // Ê∏ÖÈô§ÂèØËÉΩÂ∞éËá¥ÂïèÈ°åÁöÑÂÖÉÊï∏Êìö
        
        // Êõ¥Êñ∞ËΩâÁ¢ºÁãÄÊÖã
        Task { @MainActor in
            isTranscoding = true
            transcodingProgress = 0.0
        }
        
        // Áõ£ÊéßÈÄ≤Â∫¶
        let timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { timer in
            let progress = validExportSession.progress
            Task { @MainActor in
                self.transcodingProgress = progress
                progressHandler(progress)
            }
            
            if validExportSession.status != .exporting {
                timer.invalidate()
            }
        }
        
        // ÈñãÂßãËΩâÁ¢º
        validExportSession.exportAsynchronously { [weak self] in
            DispatchQueue.main.async {
                timer.invalidate()
                
                guard let self = self else { return }
                
                // Ê∏ÖÈô§Ê¥ªÂãïÁöÑ export session
                self.activeExportSession = nil
                self.isTranscoding = false
                
                switch validExportSession.status {
                case .completed:
                    print("ThumbnailCache: ‚úÖ H.264 transcoding completed successfully")
                    self.transcodingProgress = 1.0
                    
                    // Âª∫Á´ãÊñ∞ÁöÑ AVAsset
                    let h264Asset = AVAsset(url: outputURL)
                    completion(.success(h264Asset))
                    
                    // Ëá™ÂãïË®≠ÂÆöËΩâÁ¢ºÂæåÁöÑ asset
                    self.setAsset(h264Asset)
                    
                case .failed:
                    let error = validExportSession.error
                    print("ThumbnailCache: ‚ùå Transcoding failed: \(error?.localizedDescription ?? "Unknown error")")
                    
                    // Ê∏ÖÁêÜÂ§±ÊïóÁöÑÊ™îÊ°à
                    try? FileManager.default.removeItem(at: outputURL)
                    completion(.failure(.exportFailed(error)))
                    
                case .cancelled:
                    print("ThumbnailCache: ‚ö†Ô∏è Transcoding was cancelled")
                    try? FileManager.default.removeItem(at: outputURL)
                    completion(.failure(.cancelled))
                    
                default:
                    print("ThumbnailCache: ‚ö†Ô∏è Transcoding ended with unexpected status: \(validExportSession.status.rawValue)")
                    completion(.failure(.unknownError))
                }
            }
        }
    }
    
    /// Âª∫Á´ãËΩâÁ¢ºÊ™îÊ°àÁöÑ URL
    private func createTranscodedVideoURL(for phAsset: PHAsset) -> URL {
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let transcodedFolder = documentsPath.appendingPathComponent("TranscodedVideos")
        
        // Âª∫Á´ãË≥áÊñôÂ§æÂ¶ÇÊûú‰∏çÂ≠òÂú®
        try? FileManager.default.createDirectory(at: transcodedFolder, withIntermediateDirectories: true)
        
        // ‰ΩøÁî® PHAsset ÁöÑ localIdentifier ‰ΩúÁÇ∫Ê™îÂêç
        let filename = "\(phAsset.localIdentifier)_h264.mp4"
        return transcodedFolder.appendingPathComponent(filename)
    }
    
    /// Ê™¢Êü•ÊòØÂê¶Â∑≤Á∂ìÊúâËΩâÁ¢ºÁâàÊú¨
    func hasTranscodedVersion(for phAsset: PHAsset) -> Bool {
        let transcodedURL = createTranscodedVideoURL(for: phAsset)
        return FileManager.default.fileExists(atPath: transcodedURL.path)
    }
    
    /// ÂèñÂæóËΩâÁ¢ºÁâàÊú¨ÁöÑ AVAsset
    func getTranscodedAsset(for phAsset: PHAsset) -> AVAsset? {
        guard hasTranscodedVersion(for: phAsset) else { return nil }
        let transcodedURL = createTranscodedVideoURL(for: phAsset)
        return AVAsset(url: transcodedURL)
    }
    
    /// Ê∏ÖÁêÜËΩâÁ¢ºÊ™îÊ°à
    func cleanupTranscodedFiles() {
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let transcodedFolder = documentsPath.appendingPathComponent("TranscodedVideos")
        
        do {
            let files = try FileManager.default.contentsOfDirectory(at: transcodedFolder, includingPropertiesForKeys: nil)
            for file in files {
                try FileManager.default.removeItem(at: file)
                print("ThumbnailCache: üóëÔ∏è Cleaned up transcoded file: \(file.lastPathComponent)")
            }
        } catch {
            print("ThumbnailCache: ‚ùå Error cleaning up transcoded files: \(error)")
        }
    }
    
    /// ÂèñÊ∂àÊ≠£Âú®ÈÄ≤Ë°åÁöÑËΩâÁ¢º
    func cancelTranscoding() {
        guard let exportSession = activeExportSession, isTranscoding else {
            print("ThumbnailCache: No active transcoding to cancel")
            return
        }
        
        print("ThumbnailCache: üõë Cancelling transcoding...")
        exportSession.cancelExport()
        
        // Ê∏ÖÈô§ÁãÄÊÖã
        activeExportSession = nil
        Task { @MainActor in
            isTranscoding = false
            transcodingProgress = 0.0
        }
    }
}

/// Priority levels for thumbnail generation to optimize performance
enum ThumbnailGenerationPriority {
    case high    // For visible thumbnails - generated immediately
    case normal  // For preload thumbnails - generated with lower priority
    case low     // For background preloading - generated when system is idle
}

@MainActor
class ThumbnailCache: ObservableObject {
    // MARK: - Properties
    
    private let cache = NSCache<NSNumber, UIImage>()
    private var imageGenerator: AVAssetImageGenerator?
    private let thumbnailQueue = DispatchQueue(label: "thumbnail.generation", qos: .userInitiated)
    private var asset: AVAsset?
    
    @Published var thumbnails: [TimeInterval: UIImage] = [:]
    @Published var isGenerating: Bool = false
    
    // Transcoding support
    private var activeExportSession: AVAssetExportSession?
    @Published var isTranscoding: Bool = false
    @Published var transcodingProgress: Float = 0.0
    
    // Cache configuration
    private let maxCacheSize: Int = 80 // Ê∏õÂ∞ëÂø´ÂèñÊï∏Èáè‰ª•Âõ†ÊáâÊõ¥È´òËß£ÊûêÂ∫¶
    private let thumbnailSize = CGSize(width: 240, height: 135) // 16:9 aspect ratio, 2x resolution
    
    // MARK: - Initialization
    
    init(asset: AVAsset? = nil) {
        self.asset = asset
        
        if let asset = asset {
            self.imageGenerator = AVAssetImageGenerator(asset: asset)
            configureImageGenerator()
        } else {
            self.imageGenerator = nil
        }
        
        setupCache()
        setupMemoryWarningObserver()
        setupPerformanceIntegration()
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    // MARK: - Cache Configuration
    
    private func setupCache() {
        cache.countLimit = maxCacheSize
        cache.totalCostLimit = maxCacheSize * Int(thumbnailSize.width * thumbnailSize.height * 4) // 4 bytes per pixel
    }
    
    private func configureImageGenerator() {
        guard let generator = imageGenerator else { return }
        
        generator.maximumSize = thumbnailSize
        generator.requestedTimeToleranceBefore = CMTime.zero
        generator.requestedTimeToleranceAfter = CMTime.zero
        generator.appliesPreferredTrackTransform = true
        
        // ÊèêÂçáÂúñÂÉèÂìÅË≥™Ë®≠ÂÆö
        generator.apertureMode = .cleanAperture
        
        // ÂÑ™ÂåñÁîüÊàêÈÄüÂ∫¶ÁöÑË®≠ÂÆö
        if #available(iOS 16.0, *) {
            // ‰ΩøÁî®ËºÉÂø´ÁöÑÁîüÊàêÊ®°Âºè
            generator.videoComposition = nil // Ê∏õÂ∞ëËôïÁêÜË§áÈõúÂ∫¶
        }
        
        print("ThumbnailCache: Image generator configured for optimal performance")
    }
    
    // MARK: - Memory Management
    
    private func setupMemoryWarningObserver() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleMemoryWarning),
            name: UIApplication.didReceiveMemoryWarningNotification,
            object: nil
        )
    }
    
    @objc private func handleMemoryWarning() {
        Task { @MainActor in
            clearCache()
        }
    }
    
    func clearCache() {
        cache.removeAllObjects()
        thumbnails.removeAll()
    }
    
    // MARK: - Asset Management
    
    func setAsset(_ newAsset: AVAsset) {
        print("ThumbnailCache: Setting new asset with duration: \(newAsset.duration.seconds)")
        asset = newAsset
        clearCache()
        
        // Create new image generator for the asset
        imageGenerator = AVAssetImageGenerator(asset: newAsset)
        configureImageGenerator()
        
        print("ThumbnailCache: Image generator configured successfully")
        
        // Á´ãÂç≥ÁîüÊàêÁ¨¨‰∏ÄÂÄãÁ∏ÆÂúñ (0.0 ÊôÇÈñìÈªû) Á¢∫‰øùÂø´ÈÄüÈ°ØÁ§∫
        print("ThumbnailCache: Immediately generating first thumbnail at 0.0")
        generateSingleThumbnail(for: 0.0) { image in
            if let _ = image {
                print("ThumbnailCache: First thumbnail (0.0) generated successfully")
            } else {
                print("ThumbnailCache: Failed to generate first thumbnail (0.0)")
            }
        }
        
        // Â¶ÇÊûúÂΩ±ÁâáÈï∑Â∫¶Â∑≤Áü•Ôºå‰πüÈ†êÂÖàÁîüÊàêÂπæÂÄãÈóúÈçµÊôÇÈñìÈªûÁöÑÁ∏ÆÂúñ
        let duration = newAsset.duration.seconds
        if duration > 0 && duration.isFinite {
            let keyTimes: [TimeInterval] = [0.0, min(1.0, duration/4), min(2.0, duration/2), min(4.0, duration*0.75)]
            print("ThumbnailCache: Pre-generating key thumbnails at times: \(keyTimes)")
            
            for time in keyTimes where time < duration {
                generateSingleThumbnail(for: time) { image in
                    if let _ = image {
                        print("ThumbnailCache: Key thumbnail at \(time) generated successfully")
                    }
                }
            }
        }
    }
    
    // MARK: - Thumbnail Retrieval
    
    func getThumbnail(for time: TimeInterval) -> UIImage? {
        let key = NSNumber(value: time)
        return cache.object(forKey: key)
    }
    
    func hasThumbnail(for time: TimeInterval) -> Bool {
        let key = NSNumber(value: time)
        return cache.object(forKey: key) != nil
    }
    
    // MARK: - Thumbnail Generation
    
    func generateThumbnails(for times: [TimeInterval]) {
        guard let asset = asset, let generator = imageGenerator else { return }
        
        // Filter out times that already have cached thumbnails
        let uncachedTimes = times.filter { !hasThumbnail(for: $0) }
        guard !uncachedTimes.isEmpty else { return }
        
        Task { @MainActor in
            isGenerating = true
        }
        
        thumbnailQueue.async { [weak self] in
            guard let self = self else { return }
            
            let cmTimes = uncachedTimes.map { time in
                CMTime(seconds: time, preferredTimescale: 600)
            }
            
            var generatedCount = 0
            let totalCount = cmTimes.count
            
            generator.generateCGImagesAsynchronously(forTimes: cmTimes.map { NSValue(time: $0) }) { [weak self] requestedTime, cgImage, actualTime, result, error in
                
                guard let self = self else { return }
                
                let timeInterval = CMTimeGetSeconds(requestedTime)
                
                if let cgImage = cgImage, result == .succeeded {
                    let uiImage = UIImage(cgImage: cgImage)
                    let key = NSNumber(value: timeInterval)
                    
                    // Cache the thumbnail with cost based on image size
                    let cost = Int(self.thumbnailSize.width * self.thumbnailSize.height * 4)
                    self.cache.setObject(uiImage, forKey: key, cost: cost)
                    
                    // Update published thumbnails on main thread
                    Task { @MainActor in
                        self.thumbnails[timeInterval] = uiImage
                    }
                } else if let error = error {
                    print("Thumbnail generation failed for time \(timeInterval): \(error.localizedDescription)")
                }
                
                generatedCount += 1
                
                // Update generation status when complete
                if generatedCount >= totalCount {
                    Task { @MainActor in
                        self.isGenerating = false
                    }
                }
            }
        }
    }
    
    func generateSingleThumbnail(for time: TimeInterval, completion: @escaping (UIImage?) -> Void) {
        print("ThumbnailCache: generateSingleThumbnail called for time: \(time)")
        
        guard let asset = asset else {
            print("ThumbnailCache: No asset available")
            completion(nil)
            return
        }
        
        guard let generator = imageGenerator else {
            print("ThumbnailCache: No image generator available")
            completion(nil)
            return
        }
        
        // Check cache first
        if let cachedImage = getThumbnail(for: time) {
            print("ThumbnailCache: Found cached thumbnail for time: \(time)")
            completion(cachedImage)
            return
        }
        
        print("ThumbnailCache: Generating new thumbnail for time: \(time)")
        
        thumbnailQueue.async { [weak self] in
            guard let self = self else {
                print("ThumbnailCache: Self was deallocated")
                completion(nil)
                return
            }
            
            let cmTime = CMTime(seconds: time, preferredTimescale: 600)
            print("ThumbnailCache: Attempting to generate CGImage at time: \(cmTime)")
            
            // Use the new async method instead of deprecated copyCGImage
            generator.generateCGImagesAsynchronously(forTimes: [NSValue(time: cmTime)]) { [weak self] requestedTime, cgImage, actualTime, result, error in
                guard let self = self else {
                    DispatchQueue.main.async { completion(nil) }
                    return
                }
                
                if let cgImage = cgImage, result == .succeeded {
                    let uiImage = UIImage(cgImage: cgImage)
                    
                    print("ThumbnailCache: Successfully generated thumbnail for time: \(time)")
                    
                    // Cache the thumbnail on main thread to avoid threading issues
                    DispatchQueue.main.async {
                        let key = NSNumber(value: time)
                        let cost = Int(self.thumbnailSize.width * self.thumbnailSize.height * 4)
                        self.cache.setObject(uiImage, forKey: key, cost: cost)
                        
                        // Update published thumbnails
                        self.thumbnails[time] = uiImage
                        
                        completion(uiImage)
                    }
                } else {
                    let errorMessage = error?.localizedDescription ?? "Unknown error"
                    print("ThumbnailCache: Single thumbnail generation failed for time \(time): \(errorMessage)")
                    DispatchQueue.main.async {
                        completion(nil)
                    }
                }
            }
        }
    }
    
    // MARK: - Enhanced Batch Operations
    
    func preloadThumbnails(for timeRange: ClosedRange<TimeInterval>, interval: TimeInterval = 1.0) {
        let times = stride(from: timeRange.lowerBound, through: timeRange.upperBound, by: interval).map { $0 }
        generateThumbnails(for: times)
    }
    
    /// Calculate which thumbnails are needed based on current zoom and scroll position
    /// This is the core logic for task 10 requirement 1
    func calculateNeededThumbnails(
        visibleStartTime: TimeInterval,
        visibleEndTime: TimeInterval,
        totalDuration: TimeInterval,
        pixelsPerSecond: CGFloat,
        preloadBuffer: TimeInterval = 10.0
    ) -> [TimeInterval] {
        // Ensure valid time range
        let startTime = max(0, visibleStartTime - preloadBuffer)
        let endTime = min(totalDuration, visibleEndTime + preloadBuffer)
        
        guard startTime < endTime else { return [] }
        
        // Calculate optimal thumbnail interval based on zoom level
        let thumbnailInterval = calculateOptimalThumbnailInterval(pixelsPerSecond: pixelsPerSecond)
        
        // Generate thumbnail times within the range
        var thumbnailTimes: [TimeInterval] = []
        var currentTime = startTime
        
        while currentTime <= endTime {
            thumbnailTimes.append(currentTime)
            currentTime += thumbnailInterval
        }
        
        // Filter out times that already have cached thumbnails
        return thumbnailTimes.filter { !hasThumbnail(for: $0) }
    }
    
    /// Calculate optimal thumbnail interval based on zoom level
    private func calculateOptimalThumbnailInterval(pixelsPerSecond: CGFloat) -> TimeInterval {
        switch pixelsPerSecond {
        case 0..<20:
            return 2.0  // Low zoom: fewer thumbnails, 2 second intervals
        case 20..<40:
            return 1.5  // Medium-low zoom: 1.5 second intervals
        case 40..<80:
            return 1.0  // Medium zoom: 1 second intervals
        case 80..<120:
            return 0.5  // High zoom: 0.5 second intervals
        default:
            return 0.25 // Very high zoom: 0.25 second intervals for maximum detail
        }
    }
    
    /// Generate thumbnails for visible range with priority handling
    /// This implements task 10 requirements 2 and 3
    func generateThumbnailsForVisibleRange(
        visibleStartTime: TimeInterval,
        visibleEndTime: TimeInterval,
        totalDuration: TimeInterval,
        pixelsPerSecond: CGFloat,
        priority: ThumbnailGenerationPriority = .normal
    ) {
        let neededTimes = calculateNeededThumbnails(
            visibleStartTime: visibleStartTime,
            visibleEndTime: visibleEndTime,
            totalDuration: totalDuration,
            pixelsPerSecond: pixelsPerSecond
        )
        
        guard !neededTimes.isEmpty else { return }
        
        // Separate visible and preload thumbnails for priority handling
        let visibleTimes = neededTimes.filter { time in
            time >= visibleStartTime && time <= visibleEndTime
        }
        let preloadTimes = neededTimes.filter { time in
            time < visibleStartTime || time > visibleEndTime
        }
        
        // Generate visible thumbnails first with high priority
        if !visibleTimes.isEmpty {
            generateThumbnailsWithPriority(for: visibleTimes, priority: .high)
        }
        
        // Generate preload thumbnails with normal priority
        if !preloadTimes.isEmpty {
            generateThumbnailsWithPriority(for: preloadTimes, priority: .normal)
        }
    }
    
    /// Generate thumbnails with priority handling and enhanced error recovery
    /// This implements task 10 requirements 2, 3, and 4
    private func generateThumbnailsWithPriority(
        for times: [TimeInterval],
        priority: ThumbnailGenerationPriority
    ) {
        guard let asset = asset, let generator = imageGenerator else { return }
        
        // Filter out times that already have cached thumbnails
        let uncachedTimes = times.filter { !hasThumbnail(for: $0) }
        guard !uncachedTimes.isEmpty else { return }
        
        Task { @MainActor in
            isGenerating = true
        }
        
        // Choose appropriate queue based on priority
        let queue: DispatchQueue
        switch priority {
        case .high:
            queue = DispatchQueue.main // High priority on main queue for immediate processing
        case .normal:
            queue = thumbnailQueue // Normal priority on background queue
        case .low:
            queue = DispatchQueue.global(qos: .background) // Low priority on background
        }
        
        queue.async { [weak self] in
            self?.performPriorityThumbnailGeneration(
                for: uncachedTimes,
                asset: asset,
                generator: generator,
                priority: priority
            )
        }
    }
    
    /// Perform thumbnail generation with enhanced error handling and fallback images
    /// This implements task 10 requirement 4
    private func performPriorityThumbnailGeneration(
        for times: [TimeInterval],
        asset: AVAsset,
        generator: AVAssetImageGenerator,
        priority: ThumbnailGenerationPriority
    ) {
        let cmTimes = times.map { time in
            CMTime(seconds: time, preferredTimescale: 600)
        }
        
        var generatedCount = 0
        let totalCount = cmTimes.count
        
        // Configure generator based on priority
        let configuredGenerator = AVAssetImageGenerator(asset: asset)
        configuredGenerator.appliesPreferredTrackTransform = true
        configuredGenerator.maximumSize = thumbnailSize
        
        // ÊèêÂçáÂúñÂÉèÂìÅË≥™Ë®≠ÂÆö
        configuredGenerator.apertureMode = .cleanAperture
        
        // Set tolerance based on priority
        let tolerance: CMTime
        switch priority {
        case .high:
            tolerance = CMTime.zero // Exact frames for visible thumbnails
        case .normal:
            tolerance = CMTime(seconds: 0.1, preferredTimescale: 600) // Small tolerance
        case .low:
            tolerance = CMTime(seconds: 0.2, preferredTimescale: 600) // Larger tolerance for background
        }
        
        configuredGenerator.requestedTimeToleranceBefore = tolerance
        configuredGenerator.requestedTimeToleranceAfter = tolerance
        
        configuredGenerator.generateCGImagesAsynchronously(forTimes: cmTimes.map { NSValue(time: $0) }) { [weak self] requestedTime, cgImage, actualTime, result, error in
            
            guard let self = self else { return }
            
            let timeInterval = CMTimeGetSeconds(requestedTime)
            
            if let cgImage = cgImage, result == .succeeded {
                // Successful generation
                let uiImage = UIImage(cgImage: cgImage)
                self.cacheThumbnailWithPriority(uiImage, for: timeInterval, priority: priority)
            } else {
                // Handle generation error with fallback placeholder
                self.handleThumbnailGenerationError(for: timeInterval, error: error, priority: priority)
            }
            
            generatedCount += 1
            
            // Update generation status when complete
            if generatedCount >= totalCount {
                Task { @MainActor in
                    self.isGenerating = false
                }
            }
        }
    }
    
    /// Cache thumbnail with priority-based cost calculation
    private func cacheThumbnailWithPriority(_ image: UIImage, for time: TimeInterval, priority: ThumbnailGenerationPriority) {
        let key = NSNumber(value: time)
        
        // Calculate cost based on priority (high priority thumbnails get higher cost to stay in cache longer)
        let baseCost = Int(thumbnailSize.width * thumbnailSize.height * 4)
        let priorityCost: Int
        switch priority {
        case .high:
            priorityCost = baseCost * 3 // High priority thumbnails are 3x more expensive to evict
        case .normal:
            priorityCost = baseCost * 2 // Normal priority thumbnails are 2x more expensive to evict
        case .low:
            priorityCost = baseCost // Low priority thumbnails have base cost
        }
        
        cache.setObject(image, forKey: key, cost: priorityCost)
        
        // Update published thumbnails on main thread
        Task { @MainActor in
            self.thumbnails[time] = image
        }
    }
    
    /// Handle thumbnail generation errors with appropriate fallback images
    /// This implements task 10 requirement 4 - error handling with fallback placeholder images
    private func handleThumbnailGenerationError(
        for time: TimeInterval,
        error: Error?,
        priority: ThumbnailGenerationPriority
    ) {
        // Log error for debugging
        if let error = error {
            print("Thumbnail generation failed for time \(time) with priority \(priority): \(error.localizedDescription)")
        }
        
        // Create fallback placeholder image with time information
        let fallbackImage = createErrorFallbackImage(for: time, priority: priority)
        
        // Cache the fallback image with lower cost to allow easy replacement
        let key = NSNumber(value: time)
        let fallbackCost = Int(thumbnailSize.width * thumbnailSize.height) // Lower cost for fallback images
        cache.setObject(fallbackImage, forKey: key, cost: fallbackCost)
        
        // Update published thumbnails on main thread
        Task { @MainActor in
            self.thumbnails[time] = fallbackImage
        }
    }
    
    /// Create error fallback image with time and priority information
    private func createErrorFallbackImage(for time: TimeInterval, priority: ThumbnailGenerationPriority) -> UIImage {
        let renderer = UIGraphicsImageRenderer(size: thumbnailSize)
        return renderer.image { context in
            // Background gradient based on priority
            let colors: [UIColor]
            switch priority {
            case .high:
                colors = [UIColor.systemRed.withAlphaComponent(0.3), UIColor.systemRed.withAlphaComponent(0.1)]
            case .normal:
                colors = [UIColor.systemOrange.withAlphaComponent(0.3), UIColor.systemOrange.withAlphaComponent(0.1)]
            case .low:
                colors = [UIColor.systemGray.withAlphaComponent(0.3), UIColor.systemGray.withAlphaComponent(0.1)]
            }
            
            // Create gradient
            let colorSpace = CGColorSpaceCreateDeviceRGB()
            let gradient = CGGradient(colorsSpace: colorSpace, colors: colors.map { $0.cgColor } as CFArray, locations: nil)
            
            context.cgContext.drawLinearGradient(
                gradient!,
                start: CGPoint(x: 0, y: 0),
                end: CGPoint(x: thumbnailSize.width, y: thumbnailSize.height),
                options: []
            )
            
            // Add error indicator
            let iconSize: CGFloat = 20
            let iconRect = CGRect(
                x: (thumbnailSize.width - iconSize) / 2,
                y: (thumbnailSize.height - iconSize) / 2 - 8,
                width: iconSize,
                height: iconSize
            )
            
            // Draw error icon
            UIColor.white.withAlphaComponent(0.8).setFill()
            let iconPath = UIBezierPath(ovalIn: iconRect)
            iconPath.fill()
            
            // Add exclamation mark
            UIColor.red.setFill()
            let exclamationRect = CGRect(
                x: iconRect.midX - 1,
                y: iconRect.midY - 6,
                width: 2,
                height: 8
            )
            context.cgContext.fill(exclamationRect)
            
            let dotRect = CGRect(
                x: iconRect.midX - 1,
                y: iconRect.midY + 3,
                width: 2,
                height: 2
            )
            context.cgContext.fill(dotRect)
            
            // Add time text
            let timeText = formatTimeForFallback(time)
            let attributes: [NSAttributedString.Key: Any] = [
                .foregroundColor: UIColor.white.withAlphaComponent(0.9),
                .font: UIFont.systemFont(ofSize: 9, weight: .medium),
                .strokeColor: UIColor.black.withAlphaComponent(0.5),
                .strokeWidth: -1.0
            ]
            
            let textSize = timeText.size(withAttributes: attributes)
            let textRect = CGRect(
                x: (thumbnailSize.width - textSize.width) / 2,
                y: thumbnailSize.height - textSize.height - 4,
                width: textSize.width,
                height: textSize.height
            )
            
            timeText.draw(in: textRect, withAttributes: attributes)
        }
    }
    
    /// Format time for fallback image display
    private func formatTimeForFallback(_ time: TimeInterval) -> String {
        let minutes = Int(time) / 60
        let seconds = Int(time) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    // MARK: - Cache Statistics
    
    var cacheInfo: (count: Int, memoryUsage: String) {
        let count = thumbnails.count
        let estimatedMemory = count * Int(thumbnailSize.width * thumbnailSize.height * 4)
        let memoryMB = Double(estimatedMemory) / (1024 * 1024)
        return (count, String(format: "%.1f MB", memoryMB))
    }
    
    // MARK: - Utility Methods
    
    func cancelAllOperations() {
        // Note: AVAssetImageGenerator doesn't provide direct cancellation
        // This method is here for future enhancement if needed
        Task { @MainActor in
            isGenerating = false
        }
    }
    
    func evictOldThumbnails(keepingRecent recentCount: Int = 50) {
        let sortedTimes = thumbnails.keys.sorted()
        let toRemove = sortedTimes.dropLast(recentCount)
        
        for time in toRemove {
            let key = NSNumber(value: time)
            cache.removeObject(forKey: key)
            thumbnails.removeValue(forKey: time)
        }
    }
    
    // MARK: - Performance Integration
    
    /// Setup performance monitoring integration for automatic cache cleanup
    /// This implements task 15 requirement 2: "Add memory usage monitoring and automatic cache cleanup"
    private func setupPerformanceIntegration() {
        // Listen for cache cleanup notifications from performance monitor
        NotificationCenter.default.addObserver(
            forName: NSNotification.Name("TimelineCacheCleanup"),
            object: nil,
            queue: .main
        ) { [weak self] notification in
            self?.handlePerformanceCacheCleanup(notification)
        }
        
        // Listen for zoom changes to adjust cache strategy
        NotificationCenter.default.addObserver(
            forName: NSNotification.Name("TimelineZoomChanged"),
            object: nil,
            queue: .main
        ) { [weak self] notification in
            self?.handleZoomChange(notification)
        }
    }
    
    /// Handle performance-triggered cache cleanup
    private func handlePerformanceCacheCleanup(_ notification: Notification) {
        let reason = notification.userInfo?["reason"] as? String ?? "unknown"
        print("Performing cache cleanup due to: \(reason)")
        
        if reason == "memory_critical" {
            // Aggressive cleanup for critical memory situations
            performAggressiveCacheCleanup()
        } else {
            // Standard cleanup
            performStandardCacheCleanup()
        }
    }
    
    /// Perform aggressive cache cleanup for critical memory situations
    private func performAggressiveCacheCleanup() {
        // Keep only the most recent 20 thumbnails
        evictOldThumbnails(keepingRecent: 20)
        
        // Reduce cache limits temporarily
        cache.countLimit = 50
        cache.totalCostLimit = cache.totalCostLimit / 2
        
        print("Aggressive cache cleanup completed - kept 20 recent thumbnails")
    }
    
    /// Perform standard cache cleanup
    private func performStandardCacheCleanup() {
        // Keep the most recent 50 thumbnails
        evictOldThumbnails(keepingRecent: 50)
        
        print("Standard cache cleanup completed - kept 50 recent thumbnails")
    }
    
    /// Handle zoom level changes to optimize thumbnail density
    private func handleZoomChange(_ notification: Notification) {
        guard let pixelsPerSecond = notification.userInfo?["pixelsPerSecond"] as? CGFloat,
              let currentTime = notification.userInfo?["currentTime"] as? TimeInterval else {
            return
        }
        
        // Adjust cache strategy based on zoom level
        if pixelsPerSecond > 100 {
            // High zoom - need more thumbnails, increase cache size
            cache.countLimit = min(150, maxCacheSize + 50)
        } else if pixelsPerSecond < 30 {
            // Low zoom - need fewer thumbnails, decrease cache size
            cache.countLimit = max(50, maxCacheSize - 50)
        } else {
            // Normal zoom - use default cache size
            cache.countLimit = maxCacheSize
        }
        
        print("Cache limits adjusted for zoom level: \(pixelsPerSecond)x")
    }
}

/// ËΩâÁ¢ºÂìÅË≥™ÈÅ∏È†Ö
enum TranscodingQuality {
    case low
    case medium
    case high
    
    var exportPreset: String {
        switch self {
        case .low:
            return AVAssetExportPresetLowQuality
        case .medium:
            return AVAssetExportPresetMediumQuality
        case .high:
            // ÂÑ™ÂÖà‰ΩøÁî® 1080pÔºåÂ¶ÇÊûú‰∏çÊîØÊè¥Ââá‰ΩøÁî® 720p
            return AVAssetExportPreset1920x1080
        }
    }
    
    /// Áç≤ÂèñÂÇôÁî®È†êË®≠ÔºàÂ¶ÇÊûú‰∏ªË¶ÅÈ†êË®≠‰∏çÊîØÊè¥Ôºâ
    var fallbackPreset: String? {
        switch self {
        case .high:
            return AVAssetExportPreset1280x720 // 1080p ÁöÑÂÇôÁî®ÊñπÊ°à
        default:
            return nil
        }
    }
    
    var description: String {
        switch self {
        case .low:
            return "‰ΩéÂìÅË≥™ (Ê™îÊ°àËºÉÂ∞è, Âø´ÈÄüËΩâÁ¢º)"
        case .medium:
            return "‰∏≠Á≠âÂìÅË≥™ (Âπ≥Ë°°ÈÅ∏È†Ö, Êé®Ëñ¶)"
        case .high:
            return "È´òÂìÅË≥™ 1080p (Ê™îÊ°àËºÉÂ§ß, ÊúÄ‰Ω≥ÂìÅË≥™)"
        }
    }
}

/// ËΩâÁ¢ºÈåØË™§È°ûÂûã
enum TranscodingError: Error, LocalizedError {
    case exportSessionCreationFailed
    case exportFailed(Error?)
    case cancelled
    case unknownError
    
    var errorDescription: String? {
        switch self {
        case .exportSessionCreationFailed:
            return "ÁÑ°Ê≥ïÂª∫Á´ãËΩâÁ¢ºÊúÉË©±"
        case .exportFailed(let error):
            return "ËΩâÁ¢ºÂ§±Êïó: \(error?.localizedDescription ?? "Êú™Áü•ÈåØË™§")"
        case .cancelled:
            return "ËΩâÁ¢ºÂ∑≤ÂèñÊ∂à"
        case .unknownError:
            return "Êú™Áü•ÁöÑËΩâÁ¢ºÈåØË™§"
        }
    }
}
